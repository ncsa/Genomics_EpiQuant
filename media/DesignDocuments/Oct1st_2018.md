# Current Status

## SPAEML

* SPAEML works given input formatted in a clean table structure where rows are sample names and columns are genotypes/phenotypes and sample names are identical between the two input files.
* The ANOVA table in the output is a Standard ANOVA table, and does not yet have AIC, BIC, mBIC yet included.
* Benchmarking had been done on iForge (using Spark Standalone), but since this benchmarking a major optimization was introduced to the code (ISSUE #6) and tests need to be redone.
* Before computing anything, the program first checks to see whether the directory that will hold the output already exists. If it does, the program exits. We do not want users to erase output files that took a lot of work to generate because they forgot to rename the output directory flag.

## File Parsers

* Little done for file conversion. We have a specialized tool that can transpose tsv data and insert a placeholder value in the top-left corner of the file to get it into the exact format that SPAEML needs

# Future Work

## Testing on Amazon

* Steven will begin scalability testing on Amazon, but he needs larger data sets than what we currently have, and will have to simulate them.
* He is experimenting with a tool called SeqSIMLA, which can simulate data and return data in PLINK's .ped/.map formats. So naturally, we will create the file parsers to deal with these simulated data sets, killing two birds with one stone.

## File Parsers

Create parsers that read in genotype and phenotype data in the following formats:

* PLINK's .ped/.map formats
* PLINK's .bed file (binary format)
* .bgen
* Others?

**Important design decision**

These parsers can either produce intermediate files in a standard format that all tools (SPAEML, LASSO, etc) can digest, or simply be attached to the beginning of each tool to parse data on the fly. If parsing data is very fast, creating an intermediate file will be unnecessary, but if it takes a long time, it makes sense to produce an intermediate file.

## LASSO

Need to explore the existing tools for running LASSO in Spark.
* Apparently, LASSO is implemented in Spark's RDD-based library (mlib; which may be deprecated in Spark3)
* There is no LASSO implementation in Spark's Dataframe library (ml)

Maybe in the interest of time, we should go ahead and use the mlib library for LASSO, even though we decided to not do that for the Ordinary Least Squares Regression mlib implementation for the SPAEML tool (Implementing the stats ourselves took a tremendous amount of time)

## SPAEML

* Need to change how the input data is digested based on decisions made in the "File Parsers section"
* Need to introduce a switch that turns epistasis off (build additive models only)

## Search Space Reduction

We expect the output from SSR to produce complex outputs. It may be worth setting up some sort of database to handle and query this data.

Some examples (note that all of these have very different purposes):
* AWS: redshift
* Apache Hive
* Apache HBase
* SparkSQL (module for iteracting with databases)

## Overall design

* Between each tool in the toolkit (LASSO, SPAEML, etc.) there needs to be output model data that can be passed to the next tool for processing.
  * To make the intermediate model data easily digestable between the tools, we can store the model data in the JSON format
     * JSON format offers benefits over a standard table-based regression model, because we can store metadata next to the regression model (genotype/phenotype info, time stamps, file locations, etc.)
     * A binary JSON format, UBJSON (Universal Binary JSON) will allow us to store large models efficiently
     
* For any tool in the pipeline, the user may decide that it should be the final tool used to build the model. This means that each tool should have a switch that allows the tool to convert the JSON formatted data into a human-readable format

* Because an analyst may *ad hoc* decide to inspect the intermediate JSON formatted data, the toolkit needs a separate tool that converts the JSON formatted data into a human-readable format (and vice versa)

