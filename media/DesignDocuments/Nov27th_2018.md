# Overview

This design document was created by Jacob Heldenbrand to summarize the state of the EpiQuant project
at the time of his departure from NCSA. It breaks down the work that has been completed, ongoing work,
and his thoughts on the future of the project.

# Completed work

## Logger

We have used the log4j logger library, because it is the same logger that Spark itself uses. We've configured the application to write a log to a file called EpiQuant.log that is separate from the verbose Spark log.

For now, the name of this file has been hard coded into the properties files. It is unclear how this could be set programatically.

To enable this functionality, one must pass the following flag to spark-submit:
```
--driver-java-options "-Dlog4j.configuration=file:/full/path/to/Genomics_EpiQuant/SPAEML/conf/log4j.properties"
```

To enable debug mode, point to the "debug mode" version of the log4j properties file:
```
--driver-java-options "-Dlog4j.configuration=file:/full/path/to/Genomics_EpiQuant/SPAEML/conf/log4j_debug.properties"
```

## Standardized Genotype/Phenotype Data representation (the FileData class)

`src/main/scala/dataformats/FileData`

We have created a class that represents the genotype/phenotype file data, which is the basic format of data
being passed into all of the statistical tools (LASSO, SPAEML, etc.)

Normally, these data is represented as a matrix with the rows as samples/individuals and the columns
representing genotypes/phenotypes. Genotype information is encoded in 0, 1, and 2's. Phenotype values 
are continuous.

The FileData class contains two fields: sampleNames and dataPairs

```
@param sampleNames The sample names
@param dataPairs tuples with (variant's name, the variant's values in the sample name's order)

Sample   VAR1  VAR2  VAR3 ...
SAMPLE1  s1v1  s1v2  s1v3  ...    =====>   sampleNames = Vector(SAMPLE1, SAMPLE2, SAMPLE3, ...)
SAMPLE2  s2v1  s2v2  s2v3  ...    =====>   dataPairs = Vector(
SAMPLE3  s3v1  s3v2  s3v3  ...                                (VAR1, Vector(s1v1, s2v1, s3v1)),
...                                                           (VAR2, Vector(s1v2, s2v2, s3v2)),
                                                              (VAR3, Vector(s1v3, s2v3, s3v3)),
                                                              ...
                                                             )
```

## File Converters

`src/main/scala/converters`

All file converters extend the abstract class FileParser, and perform two functions:

1. Turn data from the input file(s) into an instance of the FileData class
2. Write the data in the FileData class into a file in our own ".epiq" format

If converting from the original file format takes a long time, users may want to save the data in the temporary .epiq
format, which can be read into the statical programs easily.

### .epiq format

This format makes it easier to create a data structure where variants/phenotypes are paired with their values, as every
line has all of the information for an individual entry.

Usually, one thinks of samples as rows and variants/phenotypes as columns

```
(Typical genotype table)               (Typical phenotype table)
Sample SNP1 SNP2 SNP3 ... SNPM         Sample  Pheno1  Pheno2 ...
A      A1   A2   A3       AM           A       A_Ph1   A_Ph2
B      B1   B2   B3       BM           B       B_Ph1   B_Ph2
C      C1   C2   C3       CM           C       C_Ph1   C_Ph2
...                                    ...
N      N1   N2   N3       NM           N       N_Ph1   N_PhN
```

The ".epiq" format has rows are variants and columns are samples

(Also, a string called "Placeholder" is put in the top-left corner to make everything line up easily)
```
(genotype ".epiq" file)                  (phenotype ".epiq" file)
Placeholder A   B   C  ... N           Placeholder A      B      C     ... N
SNP1        A1  B1  C1     N1          Pheno1      A_Ph1  B_Ph1  C_Ph1     N_Ph1
SNP2        A2  B2  C2     N2          Pheno2      A_Ph2  B_Ph2  C_Ph2     N_Ph2
SNP3        A3  B3  C3     N3          ...
...
SNPM        AM  BM  CM     NM
```

### CustomFileParser

The CustomFileParser reads in data delimited with a character (default = '\t'), and the user can also specify whether
  the rows and columns need to be transposed or not (with the '--columnsAreVariants' flag). It also has the ability to
  remove certain columns specified by the user. This is useful when reading in custom simulated data.
  
### PedMapParser

The PedMapParser takes in two input files, a .ped file and a .map file. In the ped file, genotypes are encoded with the
bases of the SNP. This is turned into a three way encoding, where the genotypes are either 0, 1, or 2.

0 = homozygous major allele
1 = heterozygous with 1 major and 1 minor allele
2 = homozygous minor allele

Note that if both alleles are not major or minor (Example, A is the most frequent allele and C is the 2nd most frequent, but
the alleles for a given sample is G-T, G-G, or T-T), this is encoded as NaN (Not a number).

With this encoding, the pedmap data is turned into data in the FileData format.

## SPAEML

The SPAEML algorithm, which consists of iterative forward and backward model building steps resulting in a model, has been
implemented using a custom OLS implementation, and returns an ANOVA table.

In addition, we have a flag that allows users to choose whether to compute epistatic terms, or just eplore the additive
terms.

### OLS Regression

An ordinary least squares regression implementation was written using Breeze (a Scala wrapper around BLAS and LAPACK) to 
enable the SPAEML algorthm to execute quickly. Although the Spark mllib (the Spark library based on RDDs) has an OLS
implementation, we decided not to use it because mlib will not be supported in Spark3, in favor of the DataFrame-based ml
library.

Note that this decision was reversed in the LASSO code, were we decided to go ahead and use the mllib due to time
constraints.

### ANOVA table

The output of the SPAEML algorithm is written as an ANOVA table. Althogh Alex Lipka wanted some additional selection
criterion such as AIC, BIC, and mBIC included in the table, only AIC and BIC are currently calculated, and have not been
included in the ANOVA table output yet.

## LASSO

# Future Work

## Tasks to finish

* Add the AIC and BIC columns to the SPAEML ANOVA output table
* Compute mBIC 
* Allow SPAEML to use AIC, BIC, or mBIC as the selection criterion instead of the p-value

## Convert More File Formats

Possibly bgen... others?

## JSON Output/Intermediate Data

The output model of one analysis, say LASSO, may be used in another downstream tool, such as SPAEML. We need some sort of
  format to pass the intermediate data between programs.
  
For example, one might run LASSO in order to narrow down the number of variants to analyze with SPAEML. In this case, one
  needs to pass SPAEML the variant names included in the model, along with the original input data files so the data for
  those variants can be found.
  
We think JSON would be a good intermediate data format to hold this data. In fact, we could have the output models of all
  the statistical program be in JSON format, and then have other programs that turn these results into something more
  readable.
  
Once we have the variant names that were produced from the output of LASSO in a JSON file, and the original data stored in a
  FileData object (where the variant name is a key which points to the variant's values), we can easily get SPAEML to
  operate only on those variant values by looking them up from the key-value map.
  
## JSON to human-readable outputs

While we want to represent output models in the JSON format, we also want a converter to turn this information into
  human-readable data, in case the user wants to stop after LASSO, instead of moving on to SPAEML, for example.
